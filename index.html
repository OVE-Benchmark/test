<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OVE</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
</head>
<body>
  <!-- Title Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class=" columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              ObjVariantEnsemble: Advancing Point Cloud LLM Evaluation in Challenging Scenes with Subtly Distinguished Object
            </h1>
            <div class="is-size-5 publication-authors">
              <span>
                Qihang Cao</a><sup>1,2</sup>, 
                <a href="https://www.chenhuangxun.com/" target="_blank">Huangxun Chen</a><sup>2</sup>
              </span>
              <br>
              <span>1. Shanghai Jiao Tong University</span><br>
              <span>2. Hong Kong University of Science and Technology (Guangzhou)</span>
            </div>
            
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://doi.org/10.48550/arXiv.2412.14837" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                
                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/OVE-Benchmark/OVE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                
                <!-- Dataset link -->
                <span class="link-block">
                  <a href="https://github.com/OVE-Benchmark/OVE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google-drive"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Title Section -->

<!-- Teaser Video Section -->
<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <!-- Video Section -->
            <video poster="" id="tree" autoplay controls muted loop width="100%">
                <source src="My Movie.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>

            <!-- Comparison Section -->
            <div class="content mt-5">
                <h2 class="subtitle is-size-5 has-text-centered">
                    <span class="has-text-weight-semibold">Comparison of 3D grounding benchmarks in complex scenes:</span>
                </h2>
                <div class="columns is-centered">
                    <!-- Left Scene -->
                    <div class="column is-5 has-text-left">
                        <p class="has-text-info">
                            <strong>[Left]</strong> A scene from <strong>ScanNet/ScanRef</strong>, where the text description is insufficient for accurately locating a chair.
                        </p>
                    </div>
                    <!-- Right Scene -->
                    <div class="column is-5 has-text-left">
                        <p class="has-text-success">
                            <strong>[Right]</strong> A scene from <strong>ObjVariantEnsemble</strong>, where a model successfully identifies targets given sufficiently detailed descriptions.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End Teaser Video Section -->

<!-- OVE Dataset Visualization Section -->
<section class="section">
    <div class="container is-max-desktop">
        <!-- Main Title -->
        <h2 class="title has-text-black has-text-centered">
            Problems of Current Datasets & Advantages of OVE
        </h2>

        <!-- Benchmark Problems Section -->
        <div class="box has-background-light has-text-centered">
            <h3 class="title is-5 has-text-danger">Problems with Existing Benchmarks</h3>
            <ul class="is-size-5 has-text-left" style="max-width: 800px; margin: 0 auto;">
                <li class="mb-2">
                    <i class="fas fa-database has-text-danger"></i> <strong>Small scale and insufficient annotations.</strong>
                </li>
                <li>
                    <i class="fas fa-tools has-text-danger"></i> <strong>Lack of customizable challenge levels.</strong>
                </li>
            </ul>
        </div>

        <!-- OVE Dataset Overview: Two-Column Layout -->
        <div class="columns is-centered mt-5">

            <!-- Left Column: Dataset Scale -->
            <div class="column is-5">
                <div class="box">
                    <i class="fas fa-database fa-3x has-text-primary"></i>
                    <h3 class="is-size-5 has-text-weight-semibold mt-3">Larger & More Diverse Data</h3>
                    <p>OVE significantly outperforms existing benchmarks in terms of data volume and annotation richness.</p>

                    <!-- Dataset Comparison Image -->
                    <figure class="mt-3">
                        <img src="comparison.png" alt="Dataset Comparison" class="image">
                        <figcaption class="is-size-6 has-text-grey mt-2">
                            Comparison of dataset size and annotations: OVE vs. existing benchmarks.
                        </figcaption>
                    </figure>
                </div>
            </div>

            <!-- Right Column: Customizable Challenge Levels -->
            <div class="column is-5">
                <div class="box">
                    <i class="fas fa-tasks fa-3x has-text-info"></i>
                    <h3 class="is-size-5 has-text-weight-semibold mt-3">More Flexible Evaluation</h3>
                    <p>OVE enables difficulty adjustments based on object similarity, spatial complexity, and scene variation.</p>

                    <!-- Visualization Image -->
                    <figure class="mt-3">
                        <img src="benchmark_sum_v2.pdf" alt="Benchmark Summary" class="image">
                        <figcaption class="is-size-6 has-text-grey mt-2">
                            Four challenge levels: Loc, Loc+Shape, Loc+Color, and Loc+Class.
                        </figcaption>
                    </figure>
                </div>
            </div>

        </div>

    </div>
</section>
<!-- End OVE Dataset Visualization Section -->
  




  <!-- Abstract Section -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              3D scene understanding is an important task, and there has
              been a recent surge of research interest in aligning 3D representations of point clouds with text to empower embodied AI.
              However, due to the lack of comprehensive 3D benchmarks, the capabilities of 3D models in real-world scenes, particularly those that are challenging with subtly distinguished objects, remain insufficiently investigated. To facilitate a more thorough evaluation of 3D modelsâ€™ capabilities, we propose a scheme, ObjVariantEnsemble, to systematically introduce more scenes with specified object classes, colors, shapes, quantities, and spatial relationships to meet model evaluation needs. More importantly, we intentionally construct scenes with similar objects to a certain degree and design an LLM-VLM-cooperated annotator to capture key distinctions as annotations. The resultant benchmark can better challenge 3D models, reveal their shortcomings in understanding, and potentially aid in the further development of 3D models.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Abstract Section -->


  <!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-black">Poster</h2>

      <iframe  src="Poster_AAAI.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


  
<!-- Citation Section -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title has-text-black">Citation</h2>
    <p>
      If you use our dataset or code in your research, please cite our work using the following BibTeX entry:
    </p>
    <pre><code>@article{cao2024objvariantensemble,
  title={ObjVariantEnsemble: Advancing Point Cloud LLM Evaluation in Challenging Scenes with Subtly Distinguished Objects},
  author={Cao, Qihang and Chen, Huangxun},
  journal={arXiv preprint arXiv:2412.14837},
  year={2024}
}</code></pre>
  </div>
</section>
<!-- End Citation Section -->




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">

          <h3 class="title is-5 has-text-black">Acknowledgements</h3>

          <p style="max-width: 800px; margin: 0 auto;">
            We sincerely thank the anonymous reviewers for their valuable comments and suggestions, 
            which have been instrumental in improving and refining this paper. 
          </p>

          <p style="max-width: 800px; margin: 20px auto 0;">
            We are also deeply grateful to our friends and families for their continuous encouragement 
            throughout this research.
          </p>

          <p style="max-width: 800px; margin: 20px auto 0;">
            This work is supported by the Guangdong Provincial Key Lab of Integrated Communication, 
            Sensing and Computation for Ubiquitous Internet of Things (No.2023B1212010007).
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>
